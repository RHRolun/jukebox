{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c47fb1-3f55-469e-b9f1-ab2a8595a1e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip -q install keras \"tensorflow==2.15.1\" \"tf2onnx\" \"onnx\" \"seaborn\" \"onnxruntime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801f7dd-604c-4b45-82ad-2ee572ed9372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "import tf2onnx\n",
    "import onnx\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import onnxruntime as rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cc19be-13b7-4063-ae74-08f2400e492f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "song_properties = pd.read_parquet('https://github.com/rhoai-mlops/jukebox/raw/refs/heads/main/1-data_prep/song_properties.parquet')\n",
    "song_rankings = pd.read_parquet('https://github.com/rhoai-mlops/jukebox/raw/refs/heads/main/1-data_prep/song_rankings.parquet')\n",
    "song_properties.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b38b8a-07f3-4c08-9d48-026e843013f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "song_rankings = song_rankings.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851fc269-bd9b-4303-b79b-1554e5c66a60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = song_rankings.merge(song_properties, on='spotify_id', how='left')\n",
    "X = X[['is_explicit', 'duration_ms', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "y = song_rankings['country']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_one_hot = tf.keras.utils.to_categorical(y_encoded)\n",
    "\n",
    "# Split the data into training and testing sets so you have something to test the trained model with.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size = 0.2, shuffle = False)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size = 0.2, stratify = y_train)\n",
    "\n",
    "# Scale the data to remove mean and have unit variance. The data will be between -1 and 1, which makes it a lot easier for the model to learn than random (and potentially large) values.\n",
    "# It is important to only fit the scaler to the training data, otherwise you are leaking information about the global distribution of variables (which is influenced by the test set) into the training set.\n",
    "scaler = MinMaxScaler()\n",
    "scaled_x_train = scaler.fit_transform(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c1a425-8c72-4abb-ae81-fb86971e0718",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Path(\"models/music/1/artifacts\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(\"models/music/1/artifacts/scaler.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(scaler, handle)\n",
    "\n",
    "with open(\"models/music/1/artifacts/label_encoder.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(label_encoder, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c988d274-a415-49a3-99a1-caa2b610d7d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation = 'relu', input_dim = len(X.columns)))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(y_one_hot.shape[1], activation = 'sigmoid'))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy', 'Precision', 'Recall'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc19448c-6525-4e32-9b32-69641978fb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "history = model.fit(scaled_x_train, y_train, epochs=epochs, \\\n",
    "                    validation_data=(scaler.transform(X_val.values),y_val), \\\n",
    "                    verbose = True)\n",
    "print(\"Training of model is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c36515-4bf9-4017-bfb9-71ab3d8966e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_proto, _ = tf2onnx.convert.from_keras(model)\n",
    "os.makedirs(\"models/music/1\", exist_ok=True)\n",
    "onnx.save(model_proto, \"models/music/1/model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576e0946-0e36-42ac-821f-284949f1548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession(\"models/music/1/model.onnx\", providers=rt.get_available_providers())\n",
    "input_name = sess.get_inputs()[0].name\n",
    "output_name = sess.get_outputs()[0].name\n",
    "y_pred_temp = sess.run([output_name], {input_name: scaler.transform(X_test.values).astype(np.float32)}) \n",
    "y_pred_temp = y_pred_temp[0]\n",
    "y_pred_argmax = np.argmax(y_pred_temp, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a251400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_argmax = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e216592",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = np.sum(y_pred_argmax == y_test_argmax) / len(y_pred_argmax)\n",
    "print(\"Accuracy: \" + str(accuracy))\n",
    "\n",
    "c_matrix = confusion_matrix(y_test_argmax,y_pred_argmax)\n",
    "ax = sns.heatmap(c_matrix, cmap='Blues')\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
